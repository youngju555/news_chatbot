# import streamlit as st
# import feedparser
# import os
# import urllib.parse
# from dotenv import load_dotenv
# from openai import OpenAI

# # 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# load_dotenv()

# # --- ì„¤ì • ë° ì´ˆê¸°í™” ---
# API_KEY = os.getenv("OPENAI_API_KEY")
# API_BASE = os.getenv("OPENAI_API_BASE")  # GMS ë“± ë³„ë„ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© ì‹œ í•„ìš”
# MODEL_NAME = os.getenv("LLM_MODEL_NAME", "gpt-3.5-turbo") # ê¸°ë³¸ê°’ ì„¤ì •

# # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (GMS í˜¸í™˜ êµ¬ì¡°)
# # ë§Œì•½ GMSê°€ OpenAI SDKì™€ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” requests ë°©ì‹ì´ë¼ë©´ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
# if API_BASE:
#     client = OpenAI(api_key=API_KEY, base_url=API_BASE)
# else:
#     client = OpenAI(api_key=API_KEY)

# # í˜ì´ì§€ ì„¤ì •
# st.set_page_config(page_title="AI ë‰´ìŠ¤ íë ˆì´í„°", page_icon="ğŸ“°")
# st.title("ğŸ“° AI ë‰´ìŠ¤ ê²€ìƒ‰ ì±—ë´‡")

# # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡)
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # --- í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ---

# def get_news_data(keyword):
#     """
#     Google News RSSë¥¼ í†µí•´ í‚¤ì›Œë“œ ê´€ë ¨ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
#     Args:
#         keyword (str): ê²€ìƒ‰í•  í‚¤ì›Œë“œ
#     Returns:
#         list: ê¸°ì‚¬ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 5ê°œ)
#     """
#     encoded_keyword = urllib.parse.quote(keyword)
#     # í•œêµ­ì–´(ko), í•œêµ­ ì§€ì—­(KR) ì„¤ì •
#     rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
    
#     feed = feedparser.parse(rss_url)
#     news_items = []
    
#     if not feed.entries:
#         return []

#     # ìƒìœ„ 5ê°œ ê¸°ì‚¬ë§Œ ì¶”ì¶œ
#     for entry in feed.entries[:5]:
#         news_items.append({
#             "title": entry.title,
#             "link": entry.link,
#             "summary": entry.get('summary', 'ìš”ì•½ ì—†ìŒ')[:200] + "..." # ë„ˆë¬´ ê¸´ ìš”ì•½ì€ ìë¦„
#         })
    
#     return news_items

# def classify_intent(user_input):
#     """
#     ì‚¬ìš©ìì˜ ì…ë ¥ì´ 'ë‰´ìŠ¤ ê²€ìƒ‰'ì¸ì§€ 'ì¼ë°˜ ëŒ€í™”'ì¸ì§€ íŒë‹¨í•˜ê³ , ê²€ìƒ‰ì–´ê¹Œì§€ ì¶”ì¶œí•©ë‹ˆë‹¤.
#     Returns:
#         dict: {"type": "SEARCH", "keyword": "..."} or {"type": "CHAT", "keyword": None}
#     """
#     system_prompt = """
#     ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤.
#     ì‚¬ìš©ìì˜ ì…ë ¥ì´ 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ìµœê·¼ ì†Œì‹' ë“±ì„ ë¬»ëŠ” ê²€ìƒ‰ ìš”ì²­ì´ë¼ë©´ 'SEARCH:ê²€ìƒ‰í‚¤ì›Œë“œ' í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
#     ê²€ìƒ‰ ìš”ì²­ì´ ì•„ë‹ˆë¼ë©´ 'CHAT'ì´ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
    
#     ì˜ˆì‹œ 1: "ìš”ì¦˜ ì‚¼ì„±ì „ì ì£¼ê°€ ê¸°ì‚¬ ì¢€ ì°¾ì•„ì¤˜" -> SEARCH:ì‚¼ì„±ì „ì ì£¼ê°€
#     ì˜ˆì‹œ 2: "ì•ˆë…• ë°˜ê°€ì›Œ" -> CHAT
#     ì˜ˆì‹œ 3: "ë¯¸êµ­ ëŒ€ì„  ê²°ê³¼ ë‰´ìŠ¤ ì•Œë ¤ì¤˜" -> SEARCH:ë¯¸êµ­ ëŒ€ì„  ê²°ê³¼
#     """

#     try:
#         response = client.chat.completions.create(
#             model=MODEL_NAME,
#             messages=[
#                 {"role": "system", "content": system_prompt},
#                 {"role": "user", "content": user_input}
#             ],
#           #  temperature=0.0 # ì •í™•í•œ ë¶„ë¥˜ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
#         )
#         content = response.choices[0].message.content.strip()

#         if content.startswith("SEARCH:"):
#             keyword = content.split("SEARCH:")[1].strip()
#             return {"type": "SEARCH", "keyword": keyword}
#         else:
#             return {"type": "CHAT", "keyword": None}
            
#     except Exception as e:
#         st.error(f"ì˜ë„ íŒŒì•… ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
#         return {"type": "CHAT", "keyword": None} # ì—ëŸ¬ ì‹œ ì¼ë°˜ ëŒ€í™”ë¡œ ì²˜ë¦¬

# def get_llm_response(prompt, context_type="general", news_data=None):
#     """
#     LLMì—ê²Œ ì‘ë‹µì„ ìš”ì²­í•©ë‹ˆë‹¤. ë‰´ìŠ¤ ë°ì´í„°ê°€ ìˆì„ ê²½ìš° í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
#     """
#     messages = st.session_state.messages.copy() # ì´ì „ ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ ë³µì‚¬
    
#     system_prompt = ""
#     user_content = prompt

#     if context_type == "news_summary" and news_data:
#         system_prompt = "ë‹¹ì‹ ì€ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤. ì œê³µëœ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìš”ì•½ëœ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”. ê° ê¸°ì‚¬ì˜ ì¶œì²˜(ë§í¬)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
        
#         # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…
#         news_text = "\n".join([f"- ì œëª©: {item['title']}\n  ë§í¬: {item['link']}\n  ë‚´ìš©: {item['summary']}" for item in news_data])
#         user_content = f"ì‚¬ìš©ì ì§ˆë¬¸: {prompt}\n\n[ê²€ìƒ‰ëœ ë‰´ìŠ¤ ë°ì´í„°]\n{news_text}\n\nìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½í•´ì„œ ë‹µë³€í•´ì¤˜."
#     else:
#         system_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤."

#     # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€ (ë¦¬ìŠ¤íŠ¸ ë§¨ ì•ì—)
#     messages.insert(0, {"role": "system", "content": system_prompt})
    
#     # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ êµì²´ (ë‰´ìŠ¤ ë°ì´í„°ê°€ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
#     if context_type == "news_summary":
#         # ê¸°ì¡´ ë©”ì‹œì§€ ê¸°ë¡ì—ëŠ” ì›ë³¸ ì§ˆë¬¸ë§Œ ë‚¨ê¸°ê³ , ì´ë²ˆ ì¶”ë¡ ì—ë§Œ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì£¼ì…
#         # (êµ¬í˜„ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì´ë²ˆ í„´ì˜ ë©”ì‹œì§€ë¥¼ ì§ì ‘ êµ¬ì„±)
#         messages[-1] = {"role": "user", "content": user_content}

#     try:
#         stream = client.chat.completions.create(
#             model=MODEL_NAME,
#             messages=messages,
#             stream=True
#         )
#         return stream
#     except Exception as e:
#         return f"API í˜¸ì¶œ ì˜¤ë¥˜ ë°œìƒ: {e}"

# # --- UI ë° ë©”ì¸ ë¡œì§ ---

# # 1. ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (ì˜ˆ: ì‚¼ì„±ì „ì ë‰´ìŠ¤ ì°¾ì•„ì¤˜)"):
#     # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # 3. ë¡œì§ ì²˜ë¦¬ (Assistant ì‘ë‹µ)
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
        
#         # A. ì˜ë„ íŒë‹¨
#         intent_result = classify_intent(prompt)
        
#         # B. ë¶„ê¸° ì²˜ë¦¬
#         if intent_result["type"] == "SEARCH":
#             keyword = intent_result["keyword"]
#             with st.status(f"ğŸ” '{keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
#                 # ë‰´ìŠ¤ ê²€ìƒ‰ ìˆ˜í–‰
#                 news_items = get_news_data(keyword)
                
#                 if news_items:
#                     status.update(label="ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ! ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...", state="running")
#                     # LLMì—ê²Œ ìš”ì•½ ìš”ì²­
#                     stream_response = get_llm_response(prompt, context_type="news_summary", news_data=news_items)
#                     status.update(label="ì™„ë£Œ!", state="complete", expanded=False)
#                 else:
#                     status.update(label="ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
#                     full_response = f"'{keyword}'ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
#                     stream_response = None

#         else: # CASE: ì¼ë°˜ ëŒ€í™”
#             stream_response = get_llm_response(prompt, context_type="general")

#         # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥
#         if stream_response and intent_result["type"] != "SEARCH_FAIL":
#              # ë¬¸ìì—´ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš° (ìŠ¤íŠ¸ë¦¼ ê°ì²´ì¸ ê²½ìš°)
#             if not isinstance(stream_response, str):
#                 for chunk in stream_response:
#                     if chunk.choices[0].delta.content is not None:
#                         full_response += chunk.choices[0].delta.content
#                         message_placeholder.markdown(full_response + "â–Œ")
#                 message_placeholder.markdown(full_response)
#             else:
#                 # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
#                 full_response = stream_response
#                 message_placeholder.error(full_response)
#         elif not stream_response and intent_result["type"] == "SEARCH":
#              # ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨ ë©”ì‹œì§€ ì¶œë ¥ (ìœ„ì—ì„œ ì„¤ì •í•¨)
#              message_placeholder.markdown(full_response)

#     # 4. Assistant ì‘ë‹µ ì €ì¥
#     st.session_state.messages.append({"role": "assistant", "content": full_response})

import streamlit as st
import feedparser
import os
import urllib.parse
from dotenv import load_dotenv
from openai import OpenAI

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
API_KEY = os.getenv("OPENAI_API_KEY")
API_BASE = os.getenv("OPENAI_API_BASE")
MODEL_NAME = os.getenv("LLM_MODEL_NAME", "gpt-3.5-turbo")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if API_BASE:
    client = OpenAI(api_key=API_KEY, base_url=API_BASE)
else:
    client = OpenAI(api_key=API_KEY)

# í˜ì´ì§€ ì„¤ì • (ë ˆì´ì•„ì›ƒì„ wideë¡œ í•˜ë©´ ì‚¬ì´ë“œë°”ê°€ ë” ì˜ ë³´ì…ë‹ˆë‹¤)
st.set_page_config(page_title="AI ë‰´ìŠ¤ íë ˆì´í„°", page_icon="ğŸ“°", layout="wide")
st.title("ğŸ“° AI ë‰´ìŠ¤ ê²€ìƒ‰ ì±—ë´‡")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# [ì¶”ê°€ë¨] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì  ê¸°ë¡
if "total_tokens" not in st.session_state:
    st.session_state.total_tokens = 0

# --- ì‚¬ì´ë“œë°”: ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„° (ìƒˆë¡œ ì¶”ê°€ëœ ê¸°ëŠ¥) ---
with st.sidebar:
    st.header("ğŸ“Š ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°")
    st.info("APIì—ì„œëŠ” 'ë‚¨ì€ ì”ì•¡'ì„ ì•Œë ¤ì£¼ì§€ ì•Šì•„ì„œ, 'ì´ë²ˆ ëŒ€í™” ì‚¬ìš©ëŸ‰'ì„ ì¶”ì‚°í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    
    # ë¯¸í„°ê¸° í‘œì‹œ
    st.metric(label="ëˆ„ì  ì‚¬ìš© í† í° (ì¶”ì •)", value=f"{st.session_state.total_tokens:,} Tokens")
    
    # íŒ
    st.caption(f"í˜„ì¬ ëª¨ë¸: {MODEL_NAME}")
    st.caption("â€» í•œê¸€ 1ê¸€ì â‰ˆ 1~2í† í°")
    
    if st.button("ëŒ€í™” & ì‚¬ìš©ëŸ‰ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.total_tokens = 0
        st.rerun()

# --- í•µì‹¬ í•¨ìˆ˜ ì •ì˜ ---

def calc_tokens(text):
    """
    í† í° ìˆ˜ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤. (ì •í™•í•œ í† í° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ê¸€ì ìˆ˜ ê¸°ë°˜ ì¶”ì •)
    í•œê¸€/ì˜ì–´ í˜¼ìš© ì‹œ í‰ê· ì ìœ¼ë¡œ ê¸€ì ìˆ˜ì˜ 1.0~1.5ë°° ì •ë„ë¡œ ì¡ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
    """
    if not text:
        return 0
    return int(len(text) * 1.2) # ì•½ê°„ ë„‰ë„‰í•˜ê²Œ ì¡ìŒ

def get_news_data(keyword):
    encoded_keyword = urllib.parse.quote(keyword)
    rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
    
    feed = feedparser.parse(rss_url)
    news_items = []
    
    if not feed.entries:
        return []

    for entry in feed.entries[:5]:
        news_items.append({
            "title": entry.title,
            "link": entry.link,
            "summary": entry.get('summary', 'ìš”ì•½ ì—†ìŒ')[:200] + "..."
        })
    
    return news_items

def classify_intent(user_input):
    system_prompt = """
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì…ë ¥ì´ 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ìµœê·¼ ì†Œì‹' ë“±ì„ ë¬»ëŠ” ê²€ìƒ‰ ìš”ì²­ì´ë¼ë©´ 'SEARCH:ê²€ìƒ‰í‚¤ì›Œë“œ' í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    ê²€ìƒ‰ ìš”ì²­ì´ ì•„ë‹ˆë¼ë©´ 'CHAT'ì´ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
    """
    
    # ì˜ë„ íŒŒì•…ì— ì“°ì¸ í† í°ë„ ê³„ì‚° (ì…ë ¥ + ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
    input_tokens = calc_tokens(system_prompt + user_input)

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ]
            # temperature ì‚­ì œë¨ (GMS í˜¸í™˜)
        )
        content = response.choices[0].message.content.strip()
        
        # ì¶œë ¥ í† í° ê³„ì‚°
        output_tokens = calc_tokens(content)
        st.session_state.total_tokens += (input_tokens + output_tokens) # ëˆ„ì 

        if content.startswith("SEARCH:"):
            keyword = content.split("SEARCH:")[1].strip()
            return {"type": "SEARCH", "keyword": keyword}
        else:
            return {"type": "CHAT", "keyword": None}
            
    except Exception as e:
        st.error(f"ì˜ë„ íŒŒì•… ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return {"type": "CHAT", "keyword": None}

def get_llm_response(prompt, context_type="general", news_data=None):
    messages = st.session_state.messages.copy()
    
    system_prompt = ""
    user_content = prompt

    if context_type == "news_summary" and news_data:
        system_prompt = "ë‹¹ì‹ ì€ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤. ì œê³µëœ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìš”ì•½ëœ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”. ê° ê¸°ì‚¬ì˜ ì¶œì²˜(ë§í¬)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
        news_text = "\n".join([f"- ì œëª©: {item['title']}\n  ë§í¬: {item['link']}\n  ë‚´ìš©: {item['summary']}" for item in news_data])
        user_content = f"ì‚¬ìš©ì ì§ˆë¬¸: {prompt}\n\n[ê²€ìƒ‰ëœ ë‰´ìŠ¤ ë°ì´í„°]\n{news_text}\n\nìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½í•´ì„œ ë‹µë³€í•´ì¤˜."
    else:
        system_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤."

    messages.insert(0, {"role": "system", "content": system_prompt})
    
    if context_type == "news_summary":
        messages[-1] = {"role": "user", "content": user_content}

    # ì…ë ¥ í”„ë¡¬í”„íŠ¸ì˜ í† í° ê³„ì‚° (ëŒ€í™” ê¸°ë¡ ì „ì²´ + ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
    all_text = "".join([m["content"] for m in messages])
    input_tokens = calc_tokens(all_text)

    try:
        stream = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            stream=True
        )
        return stream, input_tokens # ìŠ¤íŠ¸ë¦¼ ê°ì²´ì™€ ì…ë ¥ í† í° ìˆ˜ ë°˜í™˜
    except Exception as e:
        return f"API í˜¸ì¶œ ì˜¤ë¥˜ ë°œìƒ: {e}", 0

# --- UI ë° ë©”ì¸ ë¡œì§ ---

# 1. ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (ì˜ˆ: ì‚¼ì„±ì „ì ë‰´ìŠ¤ ì°¾ì•„ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # A. ì˜ë„ íŒë‹¨
        intent_result = classify_intent(prompt)
        
        # B. ë¶„ê¸° ì²˜ë¦¬
        stream_response = None
        input_tokens_estimate = 0
        
        if intent_result["type"] == "SEARCH":
            keyword = intent_result["keyword"]
            with st.status(f"ğŸ” '{keyword}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
                news_items = get_news_data(keyword)
                
                if news_items:
                    status.update(label="ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ! ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...", state="running")
                    # LLMì—ê²Œ ìš”ì•½ ìš”ì²­ (ìŠ¤íŠ¸ë¦¼ê³¼ ì…ë ¥ í† í° ìˆ˜ ë°›ê¸°)
                    stream_response, input_tokens_estimate = get_llm_response(prompt, context_type="news_summary", news_data=news_items)
                    status.update(label="ì™„ë£Œ!", state="complete", expanded=False)
                else:
                    status.update(label="ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", state="error")
                    full_response = f"'{keyword}'ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                    stream_response = None

        else: # CASE: ì¼ë°˜ ëŒ€í™”
            stream_response, input_tokens_estimate = get_llm_response(prompt, context_type="general")

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥
        if stream_response and intent_result["type"] != "SEARCH_FAIL":
            if not isinstance(stream_response, str):
                for chunk in stream_response:
                    if chunk.choices[0].delta.content is not None:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
                
                # [ì¶”ê°€ë¨] ì‘ë‹µ ì™„ë£Œ í›„ í† í° ì •ì‚°
                output_tokens_estimate = calc_tokens(full_response)
                total_turn_tokens = input_tokens_estimate + output_tokens_estimate
                st.session_state.total_tokens += total_turn_tokens # ì‚¬ì´ë“œë°” ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ëˆ„ì 
                
                # ì‚¬ì´ë“œë°” ì¦‰ì‹œ ê°±ì‹ ì„ ìœ„í•´ rerun (ì„ íƒì‚¬í•­, ë„ˆë¬´ ê¹œë¹¡ì´ë©´ ì œê±° ê°€ëŠ¥)
                # st.rerun() 
            else:
                full_response = stream_response
                message_placeholder.error(full_response)
        elif not stream_response and intent_result["type"] == "SEARCH":
             message_placeholder.markdown(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})